{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b948149d-8165-40e7-805d-182b44739476",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate."
   ]
  },
  {
   "cell_type": "raw",
   "id": "441f6078-54dc-4a6a-9f4f-2ba798c43ede",
   "metadata": {},
   "source": [
    "Linear regression and logistic regression are both used to make predictions, but they are used for different types of problems.\n",
    "\n",
    "Linear regression is used when we want to predict a number. For example, predicting a student’s marks based on study hours. It draws a straight line to best fit the data and gives continuous values like 75.5, 82.2, etc.\n",
    "\n",
    "Logistic regression is used when we want to predict categories, especially yes or no type answers. For example, predicting if a person will get a loan approved (Yes/No) based on their income and credit score. It gives results in the form of probabilities and classifies them into categories.\n",
    "\n",
    "A scenario where logistic regression is more appropriate:\n",
    "Imagine a bank wants to know if a customer is likely to default on a loan (Yes or No). Since the answer is binary (two options), logistic regression is the right choice, not linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1838f-a4a4-4fe8-b01e-c408dfdf8dcd",
   "metadata": {},
   "source": [
    "Q2. What is the cost function used in logistic regression, and how is it optimized?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a3c7078-0654-4ccc-9668-c3bce070aadc",
   "metadata": {},
   "source": [
    "In logistic regression, we try to predict things that have only two possible answers—like yes or no, 0 or 1, spam or not spam. To measure how well the model is doing, we use something called a cost function, and the one used here is called log loss or binary cross-entropy.\n",
    "\n",
    "it is like  the model gives a probability (like 0.8 or 0.2) for whether something is true. If the model says there’s an 80% chance of spam, but it’s actually not spam, then the model is quite wrong—and the cost will be high. If the model gives a high probability for the correct answer, the cost will be low. So, the cost function tells us how far off our predictions are.\n",
    "\n",
    "To improve the predictions, we use a method called gradient descent. Imagine you're walking down a hill to find the lowest point (least error), but in a blindfolded. You take small steps in the direction that feels like downhill. The model does the same—it keeps changing its values step by step to reduce the cost and become more accurate. Over time, the model learns the best way to make correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fcb06e-e1e2-486d-b667-6c185617eff5",
   "metadata": {},
   "source": [
    "Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "raw",
   "id": "21bb8d55-9d07-46dc-b6ce-2f4d074a1e26",
   "metadata": {},
   "source": [
    "Regularization is a technique used in logistic regression to prevent overfitting. Overfitting happens when the model learns not just the main patterns but also the noise or small random details in the training data. This makes it perform well on training data but poorly on new, unseen data.\n",
    "\n",
    "Think of it like a student who memorizes the textbook word by word instead of understanding the concepts. They may do great in practice tests but struggle in real exams with new questions.\n",
    "\n",
    "Regularization helps by controlling or limiting the model’s learning. It does this by adding a penalty to the cost function when the model’s values (called coefficients or weights) become too large. This pushes the model to stay simple and focus on the most important patterns.\n",
    "\n",
    "There are two types: L1 (Lasso) and L2 (Ridge). Both help the model stay balanced and generalize better to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3dd80-f061-405f-a81e-2d32466ba501",
   "metadata": {},
   "source": [
    "Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0eef5a3b-327c-4f56-b183-2841d5701bfa",
   "metadata": {},
   "source": [
    "The ROC (Receiver Operating Characteristic) curve is a graph used to evaluate how well a logistic regression model can separate two classes — like predicting whether a person has a disease or not. In simple terms, it shows how good the model is at telling the difference between \"yes\" and \"no\" outcomes.\n",
    "\n",
    "The ROC curve plots two things:\n",
    "True Positive Rate (Sensitivity) on the Y-axis — how many actual positives the model correctly identifies.\n",
    "False Positive Rate on the X-axis — how many negatives the model wrongly says are positive.\n",
    "A good model will have a curve that goes closer to the top-left corner. The area under the ROC curve (AUC) tells us how well the model performs overall:\n",
    "\n",
    "AUC = 1 means perfect prediction.\n",
    "AUC = 0.5 means random guessing.\n",
    "\n",
    "So, the ROC curve helps us see if the model is reliable or just guessing, even when the data is imbalanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
